{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVERAGE STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patterns.abstract import StructuredExplanation\n",
    "from patterns.abstract import AbstractPattern\n",
    "from patterns.entailment import *\n",
    "from patterns.contradiction import * \n",
    "from patterns.neutral import *\n",
    "import pandas as pd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/cleaned_esnli_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entaiilment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define analysis functions\n",
    "patterns = [RephrasingPattern(), ImplicationPattern(), EquivalencePattern(), IfThenPattern(), ClassificationPattern()]\n",
    "get_highlights = lambda n, r: ast.literal_eval(r[f'Sentence1_Highlighted_Ordered_{n}']) + ast.literal_eval(r[f'Sentence2_Highlighted_Ordered_{n}'])\n",
    "apply_patterns = lambda n, x: [pattern(nlp(x[f'Explanation_{n}']), get_highlights(n, x)) for pattern in patterns]\n",
    "concat = lambda x: AbstractPattern.concatenate_explanations(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_results = data[data[\"gold_label\"] == \"entailment\"].copy()\n",
    "\n",
    "ent_results['Explanation_1_Result'] = ent_results.apply(partial(apply_patterns, 1), axis=1)\n",
    "ent_results['Explanation_2_Result'] = ent_results.apply(partial(apply_patterns, 2), axis=1)\n",
    "ent_results['Explanation_3_Result'] = ent_results.apply(partial(apply_patterns, 3), axis=1)\n",
    "\n",
    "ent_output = ent_results[[\n",
    "    'Sentence1', 'Sentence2',\n",
    "    'Sentence1_Highlighted_Ordered_1', 'Sentence2_Highlighted_Ordered_1',\n",
    "    'Explanation_1', 'Explanation_1_Result',\n",
    "    'Sentence1_Highlighted_Ordered_2', 'Sentence2_Highlighted_Ordered_2',\n",
    "    'Explanation_2', 'Explanation_2_Result',\n",
    "    'Sentence1_Highlighted_Ordered_3', 'Sentence2_Highlighted_Ordered_3',\n",
    "    'Explanation_3', 'Explanation_3_Result',\n",
    "]]\n",
    "\n",
    "ent_output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Entailment) Dataset coverage: 74.52%\n"
     ]
    }
   ],
   "source": [
    "## compute coverage statistics \n",
    "n_samples = len(ent_output)\n",
    "n_explanations = len(ent_output[\n",
    "    (\n",
    "        ent_output['Explanation_1_Result'].apply(any) |\n",
    "        ent_output['Explanation_2_Result'].apply(any) |\n",
    "        ent_output['Explanation_3_Result'].apply(any)\n",
    "    )])\n",
    "\n",
    "print(f\"(Entailment) Dataset coverage: {n_explanations/n_samples*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [NotRephrasingPattern(), NotImplicationPattern(), NotEquivalencePattern(), XORPattern(), IfThenPattern(), NotClassificationPattern(), CannotBePattern()]\n",
    "get_highlights = lambda n, r: ast.literal_eval(r[f'Sentence1_Highlighted_Ordered_{n}']) + ast.literal_eval(r[f'Sentence2_Highlighted_Ordered_{n}'])\n",
    "apply_patterns = lambda n, x: [pattern(nlp(x[f'Explanation_{n}']), get_highlights(n, x)) for pattern in patterns]\n",
    "concat = lambda x: AbstractPattern.concatenate_explanations(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_results = data[data[\"gold_label\"] == \"contradiction\"].copy()\n",
    "\n",
    "con_results['Explanation_1_Result'] = con_results.apply(partial(apply_patterns, 1), axis=1)\n",
    "con_results['Explanation_2_Result'] = con_results.apply(partial(apply_patterns, 2), axis=1)\n",
    "con_results['Explanation_3_Result'] = con_results.apply(partial(apply_patterns, 3), axis=1)\n",
    "\n",
    "con_output = con_results[[\n",
    "    'Sentence1', 'Sentence2',\n",
    "    'Sentence1_Highlighted_Ordered_1', 'Sentence2_Highlighted_Ordered_1',\n",
    "    'Explanation_1', 'Explanation_1_Result',\n",
    "    'Sentence1_Highlighted_Ordered_2', 'Sentence2_Highlighted_Ordered_2',\n",
    "    'Explanation_2', 'Explanation_2_Result',\n",
    "    'Sentence1_Highlighted_Ordered_3', 'Sentence2_Highlighted_Ordered_3',\n",
    "    'Explanation_3', 'Explanation_3_Result',\n",
    "]]\n",
    "\n",
    "con_output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(contradiction) Dataset coverage: 89.68%\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(con_output)\n",
    "n_explanations = len(con_output[\n",
    "    (\n",
    "        con_output['Explanation_1_Result'].apply(any) |\n",
    "        con_output['Explanation_2_Result'].apply(any) |\n",
    "        con_output['Explanation_3_Result'].apply(any)\n",
    "    )])\n",
    "\n",
    "print(f\"(contradiction) Dataset coverage: {n_explanations/n_samples*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [NeutralImplicationPattern(), NotAllPattern()]\n",
    "get_highlights = lambda n, r: ast.literal_eval(r[f'Sentence1_Highlighted_Ordered_{n}']) + ast.literal_eval(r[f'Sentence2_Highlighted_Ordered_{n}'])\n",
    "apply_patterns = lambda n, x: [pattern(nlp(x[f'Explanation_{n}']), get_highlights(n, x)) for pattern in patterns]\n",
    "concat = lambda x: AbstractPattern.concatenate_explanations(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_results = data[data[\"gold_label\"] == \"neutral\"].copy()\n",
    "\n",
    "nn_results['Explanation_1_Result'] = nn_results.apply(partial(apply_patterns, 1), axis=1)\n",
    "nn_results['Explanation_2_Result'] = nn_results.apply(partial(apply_patterns, 2), axis=1)\n",
    "nn_results['Explanation_3_Result'] = nn_results.apply(partial(apply_patterns, 3), axis=1)\n",
    "\n",
    "nn_output = nn_results[[\n",
    "    'Sentence1', 'Sentence2',\n",
    "    'Sentence1_Highlighted_Ordered_1', 'Sentence2_Highlighted_Ordered_1',\n",
    "    'Explanation_1', 'Explanation_1_Result',\n",
    "    'Sentence1_Highlighted_Ordered_2', 'Sentence2_Highlighted_Ordered_2',\n",
    "    'Explanation_2', 'Explanation_2_Result',\n",
    "    'Sentence1_Highlighted_Ordered_3', 'Sentence2_Highlighted_Ordered_3',\n",
    "    'Explanation_3', 'Explanation_3_Result',\n",
    "]]\n",
    "\n",
    "nn_output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(neutral) Dataset coverage: 47.31%\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(nn_output)\n",
    "n_explanations = len(nn_output[\n",
    "    (\n",
    "        nn_output['Explanation_1_Result'].apply(any) |\n",
    "        nn_output['Explanation_2_Result'].apply(any) |\n",
    "        nn_output['Explanation_3_Result'].apply(any)\n",
    "    )])\n",
    "\n",
    "print(f\"(neutral) Dataset coverage: {n_explanations/n_samples*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lola-expl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
